{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hbGwRfBS7jLP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gTLgtqGY9DaX"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "FJzP_Vya7vII"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "latent_dim = 100\n",
        "batch_size = 64\n",
        "epochs = 50\n",
        "lr = 0.0002\n",
        "image_dir = \"gan_images\"\n"
      ],
      "metadata": {
        "id": "oxr57SOA8G01"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create image directory\n",
        "os.makedirs(image_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "I3IO67V78Isn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data loader\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])  # Scale images to [-1, 1]\n",
        "])"
      ],
      "metadata": {
        "id": "M57fGogv8Kcd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(root='./data', train=True, download=True, transform=transform),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "BXgOp6-m8MU1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc2a39f3-f9fe-440e-886b-8420f703a454"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 17.7MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 477kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.46MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.87MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Generator\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(512, 28 * 28),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        img = self.model(z)\n",
        "        return img.view(z.size(0), 1, 28, 28)\n"
      ],
      "metadata": {
        "id": "fnmK1y1g8Oew"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Discriminator\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(28 * 28, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        flat = img.view(img.size(0), -1)\n",
        "        return self.model(flat)\n"
      ],
      "metadata": {
        "id": "ht4P-Cjs8Td6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize models\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n"
      ],
      "metadata": {
        "id": "cYF8NoCR8Ydu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Loss and optimizers\n",
        "adversarial_loss = nn.BCELoss()\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n"
      ],
      "metadata": {
        "id": "sjigXL748a6u"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Training\n",
        "for epoch in range(epochs):\n",
        "    for i, (imgs, _) in enumerate(dataloader):\n",
        "        real_imgs = imgs.to(device)\n",
        "        valid = torch.ones(imgs.size(0), 1, device=device)\n",
        "        fake = torch.zeros(imgs.size(0), 1, device=device)\n",
        "\n",
        "        # -----------------\n",
        "        #  Train Generator\n",
        "        # -----------------\n",
        "        optimizer_G.zero_grad()\n",
        "        z = torch.randn(imgs.size(0), latent_dim, device=device)\n",
        "        gen_imgs = generator(z)\n",
        "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "        optimizer_D.zero_grad()\n",
        "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
        "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # Logging\n",
        "        if i % 200 == 0:\n",
        "            print(f\"[Epoch {epoch}/{epochs}] [Batch {i}/{len(dataloader)}] \"\n",
        "                  f\"[D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]\")\n",
        "\n",
        "    # Save generated images\n",
        "    save_image(gen_imgs.data[:25], f\"{image_dir}/{epoch:03d}.png\", nrow=5, normalize=True)\n",
        "print(\"Training complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrCimZeK8dpn",
        "outputId": "f0d53c04-971a-47c0-fe5a-6fd2bee035c7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 0/50] [Batch 0/938] [D loss: 0.6849] [G loss: 0.7098]\n",
            "[Epoch 0/50] [Batch 200/938] [D loss: 0.4949] [G loss: 0.7402]\n",
            "[Epoch 0/50] [Batch 400/938] [D loss: 0.2340] [G loss: 1.2070]\n",
            "[Epoch 0/50] [Batch 600/938] [D loss: 0.2481] [G loss: 1.2098]\n",
            "[Epoch 0/50] [Batch 800/938] [D loss: 0.0888] [G loss: 2.3117]\n",
            "[Epoch 1/50] [Batch 0/938] [D loss: 0.0760] [G loss: 2.0366]\n",
            "[Epoch 1/50] [Batch 200/938] [D loss: 0.0745] [G loss: 2.3250]\n",
            "[Epoch 1/50] [Batch 400/938] [D loss: 0.1769] [G loss: 1.2152]\n",
            "[Epoch 1/50] [Batch 600/938] [D loss: 0.0843] [G loss: 2.5524]\n",
            "[Epoch 1/50] [Batch 800/938] [D loss: 0.1210] [G loss: 4.0576]\n",
            "[Epoch 2/50] [Batch 0/938] [D loss: 0.1034] [G loss: 2.7133]\n",
            "[Epoch 2/50] [Batch 200/938] [D loss: 0.0646] [G loss: 3.2116]\n",
            "[Epoch 2/50] [Batch 400/938] [D loss: 0.1206] [G loss: 1.6659]\n",
            "[Epoch 2/50] [Batch 600/938] [D loss: 0.0539] [G loss: 4.0423]\n",
            "[Epoch 2/50] [Batch 800/938] [D loss: 0.1896] [G loss: 1.7076]\n",
            "[Epoch 3/50] [Batch 0/938] [D loss: 0.5081] [G loss: 0.4885]\n",
            "[Epoch 3/50] [Batch 200/938] [D loss: 0.4974] [G loss: 0.4796]\n",
            "[Epoch 3/50] [Batch 400/938] [D loss: 0.1758] [G loss: 1.6095]\n",
            "[Epoch 3/50] [Batch 600/938] [D loss: 0.2094] [G loss: 5.2079]\n",
            "[Epoch 3/50] [Batch 800/938] [D loss: 0.1974] [G loss: 2.1479]\n",
            "[Epoch 4/50] [Batch 0/938] [D loss: 0.1086] [G loss: 3.6496]\n",
            "[Epoch 4/50] [Batch 200/938] [D loss: 0.0521] [G loss: 2.9954]\n",
            "[Epoch 4/50] [Batch 400/938] [D loss: 0.2349] [G loss: 2.2561]\n",
            "[Epoch 4/50] [Batch 600/938] [D loss: 0.1086] [G loss: 2.2643]\n",
            "[Epoch 4/50] [Batch 800/938] [D loss: 0.0600] [G loss: 4.1978]\n",
            "[Epoch 5/50] [Batch 0/938] [D loss: 0.0447] [G loss: 5.5137]\n",
            "[Epoch 5/50] [Batch 200/938] [D loss: 0.1262] [G loss: 1.9634]\n",
            "[Epoch 5/50] [Batch 400/938] [D loss: 2.0222] [G loss: 0.0960]\n",
            "[Epoch 5/50] [Batch 600/938] [D loss: 0.0705] [G loss: 2.9174]\n",
            "[Epoch 5/50] [Batch 800/938] [D loss: 0.1648] [G loss: 1.6068]\n",
            "[Epoch 6/50] [Batch 0/938] [D loss: 0.1173] [G loss: 6.4297]\n",
            "[Epoch 6/50] [Batch 200/938] [D loss: 0.0212] [G loss: 6.8638]\n",
            "[Epoch 6/50] [Batch 400/938] [D loss: 0.0970] [G loss: 3.3055]\n",
            "[Epoch 6/50] [Batch 600/938] [D loss: 0.0513] [G loss: 3.8626]\n",
            "[Epoch 6/50] [Batch 800/938] [D loss: 0.0279] [G loss: 3.1025]\n",
            "[Epoch 7/50] [Batch 0/938] [D loss: 0.0000] [G loss: 71.3294]\n",
            "[Epoch 7/50] [Batch 200/938] [D loss: 0.0000] [G loss: 71.6504]\n",
            "[Epoch 7/50] [Batch 400/938] [D loss: 0.0000] [G loss: 71.3266]\n",
            "[Epoch 7/50] [Batch 600/938] [D loss: 0.0000] [G loss: 71.5652]\n",
            "[Epoch 7/50] [Batch 800/938] [D loss: 0.0000] [G loss: 71.2650]\n",
            "[Epoch 8/50] [Batch 0/938] [D loss: 0.0000] [G loss: 71.3081]\n",
            "[Epoch 8/50] [Batch 200/938] [D loss: 0.0000] [G loss: 71.5475]\n",
            "[Epoch 8/50] [Batch 400/938] [D loss: 0.0000] [G loss: 71.2049]\n",
            "[Epoch 8/50] [Batch 600/938] [D loss: 0.0000] [G loss: 71.5383]\n",
            "[Epoch 8/50] [Batch 800/938] [D loss: 0.0000] [G loss: 71.9478]\n",
            "[Epoch 9/50] [Batch 0/938] [D loss: 0.0000] [G loss: 70.9637]\n",
            "[Epoch 9/50] [Batch 200/938] [D loss: 0.0000] [G loss: 71.4579]\n",
            "[Epoch 9/50] [Batch 400/938] [D loss: 0.0000] [G loss: 71.4957]\n",
            "[Epoch 9/50] [Batch 600/938] [D loss: 0.0000] [G loss: 71.2656]\n",
            "[Epoch 9/50] [Batch 800/938] [D loss: 0.0000] [G loss: 71.1944]\n",
            "[Epoch 10/50] [Batch 0/938] [D loss: 0.0000] [G loss: 71.6566]\n",
            "[Epoch 10/50] [Batch 200/938] [D loss: 0.0000] [G loss: 71.9355]\n",
            "[Epoch 10/50] [Batch 400/938] [D loss: 0.0000] [G loss: 71.8670]\n",
            "[Epoch 10/50] [Batch 600/938] [D loss: 0.0000] [G loss: 71.4729]\n",
            "[Epoch 10/50] [Batch 800/938] [D loss: 0.0000] [G loss: 71.7969]\n",
            "[Epoch 11/50] [Batch 0/938] [D loss: 0.0000] [G loss: 71.5835]\n",
            "[Epoch 11/50] [Batch 200/938] [D loss: 0.0000] [G loss: 71.8200]\n",
            "[Epoch 11/50] [Batch 400/938] [D loss: 0.0000] [G loss: 71.3504]\n",
            "[Epoch 11/50] [Batch 600/938] [D loss: 0.0000] [G loss: 71.4489]\n",
            "[Epoch 11/50] [Batch 800/938] [D loss: 0.0000] [G loss: 71.5670]\n",
            "[Epoch 12/50] [Batch 0/938] [D loss: 0.0000] [G loss: 71.8056]\n",
            "[Epoch 12/50] [Batch 200/938] [D loss: 0.0000] [G loss: 71.5569]\n",
            "[Epoch 12/50] [Batch 400/938] [D loss: 0.0000] [G loss: 71.7547]\n",
            "[Epoch 12/50] [Batch 600/938] [D loss: 0.0000] [G loss: 71.0374]\n",
            "[Epoch 12/50] [Batch 800/938] [D loss: 0.0000] [G loss: 71.4793]\n",
            "[Epoch 13/50] [Batch 0/938] [D loss: 0.0000] [G loss: 71.5141]\n",
            "[Epoch 13/50] [Batch 200/938] [D loss: 0.0000] [G loss: 71.2202]\n",
            "[Epoch 13/50] [Batch 400/938] [D loss: 0.0000] [G loss: 71.3533]\n",
            "[Epoch 13/50] [Batch 600/938] [D loss: 0.0000] [G loss: 71.8066]\n",
            "[Epoch 13/50] [Batch 800/938] [D loss: 0.0000] [G loss: 71.5653]\n",
            "[Epoch 14/50] [Batch 0/938] [D loss: 0.0000] [G loss: 71.2240]\n",
            "[Epoch 14/50] [Batch 200/938] [D loss: 0.0000] [G loss: 71.4165]\n",
            "[Epoch 14/50] [Batch 400/938] [D loss: 0.0000] [G loss: 71.5034]\n",
            "[Epoch 14/50] [Batch 600/938] [D loss: 0.0000] [G loss: 71.5613]\n",
            "[Epoch 14/50] [Batch 800/938] [D loss: 0.0000] [G loss: 71.8422]\n",
            "[Epoch 15/50] [Batch 0/938] [D loss: 0.0000] [G loss: 71.8535]\n",
            "[Epoch 15/50] [Batch 200/938] [D loss: 0.0000] [G loss: 71.2695]\n",
            "[Epoch 15/50] [Batch 400/938] [D loss: 0.0000] [G loss: 71.7901]\n",
            "[Epoch 15/50] [Batch 600/938] [D loss: 0.0000] [G loss: 71.5009]\n",
            "[Epoch 15/50] [Batch 800/938] [D loss: 0.0000] [G loss: 71.5586]\n",
            "[Epoch 16/50] [Batch 0/938] [D loss: 0.0000] [G loss: 71.6568]\n",
            "[Epoch 16/50] [Batch 200/938] [D loss: 0.0000] [G loss: 71.6584]\n",
            "[Epoch 16/50] [Batch 400/938] [D loss: 0.0000] [G loss: 71.7572]\n",
            "[Epoch 16/50] [Batch 600/938] [D loss: 0.0000] [G loss: 72.0138]\n",
            "[Epoch 16/50] [Batch 800/938] [D loss: 0.0000] [G loss: 71.5372]\n",
            "[Epoch 17/50] [Batch 0/938] [D loss: 0.0000] [G loss: 71.4040]\n",
            "[Epoch 17/50] [Batch 200/938] [D loss: 0.0000] [G loss: 71.4627]\n",
            "[Epoch 17/50] [Batch 400/938] [D loss: 0.0000] [G loss: 71.3862]\n",
            "[Epoch 17/50] [Batch 600/938] [D loss: 0.0000] [G loss: 71.9480]\n",
            "[Epoch 17/50] [Batch 800/938] [D loss: 0.0000] [G loss: 71.8560]\n",
            "[Epoch 18/50] [Batch 0/938] [D loss: 0.0000] [G loss: 71.8494]\n",
            "[Epoch 18/50] [Batch 200/938] [D loss: 0.0000] [G loss: 71.9001]\n",
            "[Epoch 18/50] [Batch 400/938] [D loss: 0.0000] [G loss: 71.4918]\n",
            "[Epoch 18/50] [Batch 600/938] [D loss: 0.0000] [G loss: 70.8419]\n",
            "[Epoch 18/50] [Batch 800/938] [D loss: 0.0000] [G loss: 71.9328]\n",
            "[Epoch 19/50] [Batch 0/938] [D loss: 0.0000] [G loss: 71.8335]\n",
            "[Epoch 19/50] [Batch 200/938] [D loss: 0.0000] [G loss: 71.6327]\n",
            "[Epoch 19/50] [Batch 400/938] [D loss: 0.0000] [G loss: 72.0440]\n",
            "[Epoch 19/50] [Batch 600/938] [D loss: 0.0000] [G loss: 71.7154]\n",
            "[Epoch 19/50] [Batch 800/938] [D loss: 0.0000] [G loss: 72.3075]\n",
            "[Epoch 20/50] [Batch 0/938] [D loss: 0.0000] [G loss: 71.7752]\n",
            "[Epoch 20/50] [Batch 200/938] [D loss: 0.0000] [G loss: 72.0088]\n",
            "[Epoch 20/50] [Batch 400/938] [D loss: 0.0000] [G loss: 71.7270]\n",
            "[Epoch 20/50] [Batch 600/938] [D loss: 0.0000] [G loss: 71.9069]\n",
            "[Epoch 20/50] [Batch 800/938] [D loss: 0.0000] [G loss: 71.9420]\n",
            "[Epoch 21/50] [Batch 0/938] [D loss: 0.0000] [G loss: 72.0609]\n",
            "[Epoch 21/50] [Batch 200/938] [D loss: 0.0000] [G loss: 71.7590]\n",
            "[Epoch 21/50] [Batch 400/938] [D loss: 0.0000] [G loss: 71.9663]\n",
            "[Epoch 21/50] [Batch 600/938] [D loss: 0.0000] [G loss: 72.1400]\n",
            "[Epoch 21/50] [Batch 800/938] [D loss: 0.0000] [G loss: 71.8239]\n",
            "[Epoch 22/50] [Batch 0/938] [D loss: 0.0000] [G loss: 72.4611]\n",
            "[Epoch 22/50] [Batch 200/938] [D loss: 0.0000] [G loss: 71.9779]\n",
            "[Epoch 22/50] [Batch 400/938] [D loss: 0.0000] [G loss: 72.1010]\n",
            "[Epoch 22/50] [Batch 600/938] [D loss: 0.0000] [G loss: 72.1063]\n",
            "[Epoch 22/50] [Batch 800/938] [D loss: 0.0000] [G loss: 72.0886]\n",
            "[Epoch 23/50] [Batch 0/938] [D loss: 0.0000] [G loss: 71.9814]\n",
            "[Epoch 23/50] [Batch 200/938] [D loss: 0.0000] [G loss: 72.1176]\n",
            "[Epoch 23/50] [Batch 400/938] [D loss: 0.0000] [G loss: 71.9383]\n",
            "[Epoch 23/50] [Batch 600/938] [D loss: 0.0000] [G loss: 71.9928]\n",
            "[Epoch 23/50] [Batch 800/938] [D loss: 0.0000] [G loss: 72.3510]\n",
            "[Epoch 24/50] [Batch 0/938] [D loss: 0.0000] [G loss: 72.1091]\n",
            "[Epoch 24/50] [Batch 200/938] [D loss: 0.0000] [G loss: 72.1120]\n",
            "[Epoch 24/50] [Batch 400/938] [D loss: 0.0000] [G loss: 72.3318]\n",
            "[Epoch 24/50] [Batch 600/938] [D loss: 0.0000] [G loss: 71.9452]\n",
            "[Epoch 24/50] [Batch 800/938] [D loss: 0.0000] [G loss: 72.4385]\n",
            "[Epoch 25/50] [Batch 0/938] [D loss: 0.0000] [G loss: 72.4329]\n",
            "[Epoch 25/50] [Batch 200/938] [D loss: 0.0000] [G loss: 72.5136]\n",
            "[Epoch 25/50] [Batch 400/938] [D loss: 0.0000] [G loss: 72.2755]\n",
            "[Epoch 25/50] [Batch 600/938] [D loss: 0.0000] [G loss: 72.1682]\n",
            "[Epoch 25/50] [Batch 800/938] [D loss: 0.0000] [G loss: 72.3797]\n",
            "[Epoch 26/50] [Batch 0/938] [D loss: 0.0000] [G loss: 72.5087]\n",
            "[Epoch 26/50] [Batch 200/938] [D loss: 0.0000] [G loss: 72.4907]\n",
            "[Epoch 26/50] [Batch 400/938] [D loss: 0.0000] [G loss: 72.5488]\n",
            "[Epoch 26/50] [Batch 600/938] [D loss: 0.0000] [G loss: 72.4713]\n",
            "[Epoch 26/50] [Batch 800/938] [D loss: 0.0000] [G loss: 72.5309]\n",
            "[Epoch 27/50] [Batch 0/938] [D loss: 0.0000] [G loss: 72.9580]\n",
            "[Epoch 27/50] [Batch 200/938] [D loss: 0.0000] [G loss: 72.6324]\n",
            "[Epoch 27/50] [Batch 400/938] [D loss: 0.0000] [G loss: 72.5201]\n",
            "[Epoch 27/50] [Batch 600/938] [D loss: 0.0000] [G loss: 72.3663]\n",
            "[Epoch 27/50] [Batch 800/938] [D loss: 0.0000] [G loss: 72.6675]\n",
            "[Epoch 28/50] [Batch 0/938] [D loss: 0.0000] [G loss: 72.7150]\n",
            "[Epoch 28/50] [Batch 200/938] [D loss: 0.0000] [G loss: 73.1348]\n",
            "[Epoch 28/50] [Batch 400/938] [D loss: 0.0000] [G loss: 72.4861]\n",
            "[Epoch 28/50] [Batch 600/938] [D loss: 0.0000] [G loss: 72.8355]\n",
            "[Epoch 28/50] [Batch 800/938] [D loss: 0.0000] [G loss: 73.2556]\n",
            "[Epoch 29/50] [Batch 0/938] [D loss: 0.0000] [G loss: 72.8924]\n",
            "[Epoch 29/50] [Batch 200/938] [D loss: 0.0000] [G loss: 73.0211]\n",
            "[Epoch 29/50] [Batch 400/938] [D loss: 0.0000] [G loss: 73.0766]\n",
            "[Epoch 29/50] [Batch 600/938] [D loss: 0.0000] [G loss: 73.1183]\n",
            "[Epoch 29/50] [Batch 800/938] [D loss: 0.0000] [G loss: 73.1886]\n",
            "[Epoch 30/50] [Batch 0/938] [D loss: 0.0000] [G loss: 73.0575]\n",
            "[Epoch 30/50] [Batch 200/938] [D loss: 0.0000] [G loss: 73.1410]\n",
            "[Epoch 30/50] [Batch 400/938] [D loss: 0.0000] [G loss: 72.9178]\n",
            "[Epoch 30/50] [Batch 600/938] [D loss: 0.0000] [G loss: 73.1723]\n",
            "[Epoch 30/50] [Batch 800/938] [D loss: 0.0000] [G loss: 73.1608]\n",
            "[Epoch 31/50] [Batch 0/938] [D loss: 0.0000] [G loss: 73.3263]\n",
            "[Epoch 31/50] [Batch 200/938] [D loss: 0.0000] [G loss: 73.4011]\n",
            "[Epoch 31/50] [Batch 400/938] [D loss: 0.0000] [G loss: 73.4180]\n",
            "[Epoch 31/50] [Batch 600/938] [D loss: 0.0000] [G loss: 73.2340]\n",
            "[Epoch 31/50] [Batch 800/938] [D loss: 0.0000] [G loss: 73.2397]\n",
            "[Epoch 32/50] [Batch 0/938] [D loss: 0.0000] [G loss: 73.5513]\n",
            "[Epoch 32/50] [Batch 200/938] [D loss: 0.0000] [G loss: 73.2000]\n",
            "[Epoch 32/50] [Batch 400/938] [D loss: 0.0000] [G loss: 73.0588]\n",
            "[Epoch 32/50] [Batch 600/938] [D loss: 0.0000] [G loss: 73.5996]\n",
            "[Epoch 32/50] [Batch 800/938] [D loss: 0.0000] [G loss: 73.5198]\n",
            "[Epoch 33/50] [Batch 0/938] [D loss: 0.0000] [G loss: 73.2158]\n",
            "[Epoch 33/50] [Batch 200/938] [D loss: 0.0000] [G loss: 73.2362]\n",
            "[Epoch 33/50] [Batch 400/938] [D loss: 0.0000] [G loss: 73.5078]\n",
            "[Epoch 33/50] [Batch 600/938] [D loss: 0.0000] [G loss: 73.4937]\n",
            "[Epoch 33/50] [Batch 800/938] [D loss: 0.0000] [G loss: 73.1469]\n",
            "[Epoch 34/50] [Batch 0/938] [D loss: 0.0000] [G loss: 73.2869]\n",
            "[Epoch 34/50] [Batch 200/938] [D loss: 0.0000] [G loss: 73.3771]\n",
            "[Epoch 34/50] [Batch 400/938] [D loss: 0.0000] [G loss: 73.6805]\n",
            "[Epoch 34/50] [Batch 600/938] [D loss: 0.0000] [G loss: 73.3130]\n",
            "[Epoch 34/50] [Batch 800/938] [D loss: 0.0000] [G loss: 73.3318]\n",
            "[Epoch 35/50] [Batch 0/938] [D loss: 0.0000] [G loss: 73.3841]\n",
            "[Epoch 35/50] [Batch 200/938] [D loss: 0.0000] [G loss: 73.3783]\n",
            "[Epoch 35/50] [Batch 400/938] [D loss: 0.0000] [G loss: 73.6397]\n",
            "[Epoch 35/50] [Batch 600/938] [D loss: 0.0000] [G loss: 73.3822]\n",
            "[Epoch 35/50] [Batch 800/938] [D loss: 0.0000] [G loss: 73.5531]\n",
            "[Epoch 36/50] [Batch 0/938] [D loss: 0.0000] [G loss: 73.7603]\n",
            "[Epoch 36/50] [Batch 200/938] [D loss: 0.0000] [G loss: 73.3735]\n",
            "[Epoch 36/50] [Batch 400/938] [D loss: 0.0000] [G loss: 73.1451]\n",
            "[Epoch 36/50] [Batch 600/938] [D loss: 0.0000] [G loss: 73.2218]\n",
            "[Epoch 36/50] [Batch 800/938] [D loss: 0.0000] [G loss: 73.6839]\n",
            "[Epoch 37/50] [Batch 0/938] [D loss: 0.0000] [G loss: 73.6219]\n",
            "[Epoch 37/50] [Batch 200/938] [D loss: 0.0000] [G loss: 73.6238]\n",
            "[Epoch 37/50] [Batch 400/938] [D loss: 0.0000] [G loss: 73.3482]\n",
            "[Epoch 37/50] [Batch 600/938] [D loss: 0.0000] [G loss: 73.5821]\n",
            "[Epoch 37/50] [Batch 800/938] [D loss: 0.0000] [G loss: 73.1404]\n",
            "[Epoch 38/50] [Batch 0/938] [D loss: 0.0000] [G loss: 73.8378]\n",
            "[Epoch 38/50] [Batch 200/938] [D loss: 0.0000] [G loss: 73.5553]\n",
            "[Epoch 38/50] [Batch 400/938] [D loss: 0.0000] [G loss: 73.7077]\n",
            "[Epoch 38/50] [Batch 600/938] [D loss: 0.0000] [G loss: 73.7388]\n",
            "[Epoch 38/50] [Batch 800/938] [D loss: 0.0000] [G loss: 73.2151]\n",
            "[Epoch 39/50] [Batch 0/938] [D loss: 0.0000] [G loss: 73.6475]\n",
            "[Epoch 39/50] [Batch 200/938] [D loss: 0.0000] [G loss: 73.7182]\n",
            "[Epoch 39/50] [Batch 400/938] [D loss: 0.0000] [G loss: 73.6207]\n",
            "[Epoch 39/50] [Batch 600/938] [D loss: 0.0000] [G loss: 73.7657]\n",
            "[Epoch 39/50] [Batch 800/938] [D loss: 0.0000] [G loss: 74.2587]\n",
            "[Epoch 40/50] [Batch 0/938] [D loss: 0.0000] [G loss: 73.9183]\n",
            "[Epoch 40/50] [Batch 200/938] [D loss: 0.0000] [G loss: 73.5351]\n",
            "[Epoch 40/50] [Batch 400/938] [D loss: 0.0000] [G loss: 73.6681]\n",
            "[Epoch 40/50] [Batch 600/938] [D loss: 0.0000] [G loss: 73.8280]\n",
            "[Epoch 40/50] [Batch 800/938] [D loss: 0.0000] [G loss: 73.6868]\n",
            "[Epoch 41/50] [Batch 0/938] [D loss: 0.0000] [G loss: 74.0577]\n",
            "[Epoch 41/50] [Batch 200/938] [D loss: 0.0000] [G loss: 73.3396]\n",
            "[Epoch 41/50] [Batch 400/938] [D loss: 0.0000] [G loss: 73.7835]\n",
            "[Epoch 41/50] [Batch 600/938] [D loss: 0.0000] [G loss: 74.0215]\n",
            "[Epoch 41/50] [Batch 800/938] [D loss: 0.0000] [G loss: 73.5292]\n",
            "[Epoch 42/50] [Batch 0/938] [D loss: 0.0000] [G loss: 73.1986]\n",
            "[Epoch 42/50] [Batch 200/938] [D loss: 0.0000] [G loss: 73.5520]\n",
            "[Epoch 42/50] [Batch 400/938] [D loss: 0.0000] [G loss: 73.7241]\n",
            "[Epoch 42/50] [Batch 600/938] [D loss: 0.0000] [G loss: 73.7929]\n",
            "[Epoch 42/50] [Batch 800/938] [D loss: 0.0000] [G loss: 73.8974]\n",
            "[Epoch 43/50] [Batch 0/938] [D loss: 0.0000] [G loss: 73.7149]\n",
            "[Epoch 43/50] [Batch 200/938] [D loss: 0.0000] [G loss: 73.7384]\n",
            "[Epoch 43/50] [Batch 400/938] [D loss: 0.0000] [G loss: 73.9814]\n",
            "[Epoch 43/50] [Batch 600/938] [D loss: 0.0000] [G loss: 73.8888]\n",
            "[Epoch 43/50] [Batch 800/938] [D loss: 0.0000] [G loss: 73.6133]\n",
            "[Epoch 44/50] [Batch 0/938] [D loss: 0.0000] [G loss: 73.7448]\n",
            "[Epoch 44/50] [Batch 200/938] [D loss: 0.0000] [G loss: 73.8343]\n",
            "[Epoch 44/50] [Batch 400/938] [D loss: 0.0000] [G loss: 73.9958]\n",
            "[Epoch 44/50] [Batch 600/938] [D loss: 0.0000] [G loss: 73.9337]\n",
            "[Epoch 44/50] [Batch 800/938] [D loss: 0.0000] [G loss: 73.5166]\n",
            "[Epoch 45/50] [Batch 0/938] [D loss: 0.0000] [G loss: 73.4853]\n",
            "[Epoch 45/50] [Batch 200/938] [D loss: 0.0000] [G loss: 73.8056]\n",
            "[Epoch 45/50] [Batch 400/938] [D loss: 0.0000] [G loss: 73.2461]\n",
            "[Epoch 45/50] [Batch 600/938] [D loss: 0.0000] [G loss: 73.9122]\n",
            "[Epoch 45/50] [Batch 800/938] [D loss: 0.0000] [G loss: 73.6321]\n",
            "[Epoch 46/50] [Batch 0/938] [D loss: 0.0000] [G loss: 73.5432]\n",
            "[Epoch 46/50] [Batch 200/938] [D loss: 0.0000] [G loss: 73.6637]\n",
            "[Epoch 46/50] [Batch 400/938] [D loss: 0.0000] [G loss: 74.0070]\n",
            "[Epoch 46/50] [Batch 600/938] [D loss: 0.0000] [G loss: 73.8763]\n",
            "[Epoch 46/50] [Batch 800/938] [D loss: 0.0000] [G loss: 73.4457]\n",
            "[Epoch 47/50] [Batch 0/938] [D loss: 0.0000] [G loss: 73.6259]\n",
            "[Epoch 47/50] [Batch 200/938] [D loss: 0.0000] [G loss: 73.4777]\n",
            "[Epoch 47/50] [Batch 400/938] [D loss: 0.0000] [G loss: 73.9073]\n",
            "[Epoch 47/50] [Batch 600/938] [D loss: 0.0000] [G loss: 73.8631]\n",
            "[Epoch 47/50] [Batch 800/938] [D loss: 0.0000] [G loss: 73.5916]\n",
            "[Epoch 48/50] [Batch 0/938] [D loss: 0.0000] [G loss: 73.5843]\n",
            "[Epoch 48/50] [Batch 200/938] [D loss: 0.0000] [G loss: 74.2459]\n",
            "[Epoch 48/50] [Batch 400/938] [D loss: 0.0000] [G loss: 73.8138]\n",
            "[Epoch 48/50] [Batch 600/938] [D loss: 0.0000] [G loss: 73.7362]\n",
            "[Epoch 48/50] [Batch 800/938] [D loss: 0.0000] [G loss: 74.1387]\n",
            "[Epoch 49/50] [Batch 0/938] [D loss: 0.0000] [G loss: 73.5912]\n",
            "[Epoch 49/50] [Batch 200/938] [D loss: 0.0000] [G loss: 73.8142]\n",
            "[Epoch 49/50] [Batch 400/938] [D loss: 0.0000] [G loss: 73.8423]\n",
            "[Epoch 49/50] [Batch 600/938] [D loss: 0.0000] [G loss: 73.5778]\n",
            "[Epoch 49/50] [Batch 800/938] [D loss: 0.0000] [G loss: 73.9396]\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2-SuwHzk8mG1"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}